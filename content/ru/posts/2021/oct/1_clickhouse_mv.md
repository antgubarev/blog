---
title: Материализованные представления и ReplacingMergeTree в Clickhouse (ч1)
date: "2021-10-20"
keywords: "clickhouse, materialized view, материализованное представление"
description: "работа с материализованным представлением в ClickHouse на примерах"
aliases: 
    - "/ru/posts/clickhousemv/"
---

В этой серии заметок будут описаны подводные камни, на которые можно наткнуться при использовании одновременно 
материализованных представлений и движка `ReplacingMergeTree` в ClickHouse-e (далее CH). Но в начале краткое погружение в термины с примерами для тех, кто возможно не знаком с CH плотно. Это первая часть, в которой опишу что такое материализованные представления, как работают и какие есть особенности.

- **Часть 1. Материализованные представления**
- Часть 2. [ReplacingMergeTree]({{< ref "/posts/2021/oct/2_clickhouse_replmt.md" >}}) 
- Часть 3. Материализованные представления и ReplacingMergeTree в одном флаконе

## Материализованные представления

Материализованное представление (МП) это по сути такая же таблица, которая хранит данные, взятые их другой таблицы. 
CH следит за вставки данных в таблице-источнике и помещает их в МП в том виде, в котором вы это описываете. Это как обычное 
представление, только данные хранятся на диске, а не формируются при каждом запросе. 
Разберем простой пример использования - логирвоание кодов ответов от нескольких приложений. 

Создаем таблицу:
```sql
CREATE TABLE responses (
    time DateTime,
    app String,
    status UInt16
) engine=MergeTree()
ORDER BY (time, app)
```

Допустим что rps суммарно на все приложения 10к. Тогда получается что через месяц мы получим 432 000 000 записей, 
а через полгода уже 2 592 000 000. Для KХ это не такие уж и большие объемы, и на хорошем железе они вряд ли создадут 
ощутимые проблемы, однако скорость ответа на некторые аналитические запросы может упасть до уровня, который будет 
не подходить под бизнес-задачи (например более 2-3с). К статусу может добавиться значение времени ответа или/и размера тела и т.д., что ощутимо увеличит таблицу.Ну а наш пример больше для того чтобы понять особенности работы. 
(Я, кстати, с проблемой времени ответа на аналитических запросах столкнулся когда уже перебиралось более 1Б записей, это для понимания возможной производительности CH).

Давайте заполним вначале таблицу какими-то данными. Предположим, что у нас три приложения: search, api, auth, на которые идет HTTP постоянно трафик.

```sql
INSERT INTO responses (time, app, status) VALUES
('2021-10-11 12:00:00', 'search', 200),
('2021-10-11 12:00:00', 'search', 200),
('2021-10-11 12:00:00', 'search', 200),
('2021-10-11 12:00:01', 'search', 200),
('2021-10-11 12:00:01', 'search', 200),
('2021-10-11 12:00:02', 'search', 500),
('2021-10-11 12:00:02', 'search', 200),

('2021-10-11 12:00:00', 'api', 200),
('2021-10-11 12:00:00', 'api', 500),
('2021-10-11 12:00:01', 'api', 200),
('2021-10-11 12:00:01', 'api', 200),
('2021-10-11 12:00:01', 'api', 403),
('2021-10-11 12:00:02', 'api', 200),

('2021-10-11 12:00:00', 'auth', 200),
('2021-10-11 12:00:01', 'auth', 500),
('2021-10-11 12:00:01', 'auth', 200),
('2021-10-11 12:00:02', 'auth', 200),
('2021-10-11 12:00:03', 'auth', 403),
('2021-10-11 12:00:03', 'auth', 200)
```

Наша задача - выводить данные суммированные поминутно по каждому приложению. Тут пока все просто:

```sql
SELECT 
    time, 
    app, 
    status,
    count(*) as count 
FROM responses 
GROUP BY time, app, status
ORDER BY time
```
Ответ:

```sql
┌────────────────time─┬─app────┬─status─┬─count─┐
│ 2021-10-11 12:00:00 │ auth   │    200 │     1 │
│ 2021-10-11 12:00:00 │ api    │    200 │     1 │
│ 2021-10-11 12:00:00 │ search │    200 │     3 │
│ 2021-10-11 12:00:00 │ api    │    500 │     1 │
│ 2021-10-11 12:00:01 │ search │    200 │     2 │
│ 2021-10-11 12:00:01 │ api    │    403 │     1 │
│ 2021-10-11 12:00:01 │ auth   │    500 │     1 │
│ 2021-10-11 12:00:01 │ auth   │    200 │     1 │
│ 2021-10-11 12:00:01 │ api    │    200 │     2 │
│ 2021-10-11 12:00:02 │ search │    200 │     1 │
│ 2021-10-11 12:00:02 │ api    │    200 │     1 │
│ 2021-10-11 12:00:02 │ search │    500 │     1 │
│ 2021-10-11 12:00:02 │ auth   │    200 │     1 │
│ 2021-10-11 12:00:03 │ auth   │    200 │     1 │
│ 2021-10-11 12:00:03 │ auth   │    403 │     1 │
└─────────────────────┴────────┴────────┴───────┘
```

Выборку смотрит заказчик, которому сильно не нравится ждать по несколько секунд или минут (как было в моем случае), а может и нас самих это не устраивает. 
Для решения этой проблемы могут хорошо подойти материализованные представления. В них можно хранить данные уже просуммированные, например, посекундно. Для нашего
примера это пойдодет лучше всего, а в реальности это могут быть и минуты или даже часы или дни.

Создаем агрегированную таблицу:

```sql
CREATE TABLE responses_by_sec (
    day     DateTime,
    app     String,
    status  UInt16,
    count   UInt64
) engine=MergeTree()
ORDER BY (day, app)
```

А теперь нужно связать агрегированную таблицу и таблицу-источник.

```sql
CREATE MATERIALIZED VIEW responses_by_sec_mat_view TO responses_by_sec AS
SELECT 
    time as day, 
    app, 
    status,
    count(*) as count 
FROM responses 
GROUP BY time, app, status
```

Если сейчас выполнить запрос 

```sql
SHOW TABLES
```

То увидим:

```sql
┌─name──────────────────────┐
│ responses                 │
│ responses_by_sec          │
│ responses_by_sec_mat_view │
└───────────────────────────┘
```

МП выглядит как обычная таблица со всеми вытекающими. Например, можно посмотреть как она устроена:

```sql
SHOW CREATE TABLE responses_by_sec_mat_view
┌─statement───────────────────────────────────────────────────────────────────────────────────┐
│ CREATE MATERIALIZED VIEW t.responses_by_sec_mat_view TO t.responses_by_sec
(
    `day` DateTime,
    `app` String,
    `status` UInt16,
    `count` UInt64
) AS
SELECT
    time AS day,
    app,
    status,
    count(*) AS count
FROM t.responses
GROUP BY
    time,
    app,
    status │
└─────────────────────────────────────────────────────────────────────────────────────────────┘
```

Теперь очищаем таблицу источник (можно просто указать `POPULATE` при создании МП и оно сразу заполнится данными, но для текущих примеров проще через очистку)

```sql
TRUNCATE responses
```

И заполняем заново тем же самы запросом, что был выше. Смотрим результат:

```sql
SELECT * FROM responses_by_sec ORDER BY day ASC

┌─────────────────day─┬─app────┬─status─┬─count─┐
│ 2021-10-11 12:00:00 │ api    │    200 │     1 │
│ 2021-10-11 12:00:00 │ api    │    500 │     1 │
│ 2021-10-11 12:00:00 │ auth   │    200 │     1 │
│ 2021-10-11 12:00:00 │ search │    200 │     3 │
│ 2021-10-11 12:00:01 │ api    │    403 │     1 │
│ 2021-10-11 12:00:01 │ api    │    200 │     2 │
│ 2021-10-11 12:00:01 │ auth   │    500 │     1 │
│ 2021-10-11 12:00:01 │ auth   │    200 │     1 │
│ 2021-10-11 12:00:01 │ search │    200 │     2 │
│ 2021-10-11 12:00:02 │ api    │    200 │     1 │
│ 2021-10-11 12:00:02 │ auth   │    200 │     1 │
│ 2021-10-11 12:00:02 │ search │    200 │     1 │
│ 2021-10-11 12:00:02 │ search │    500 │     1 │
│ 2021-10-11 12:00:03 │ auth   │    200 │     1 │
│ 2021-10-11 12:00:03 │ auth   │    403 │     1 │
└─────────────────────┴────────┴────────┴───────┘
```

Данные уже просуммированы по секундно. Если теперь выборки для клиентов делать из этой новой таблицы, то это в сотни и иногда даже тысячи раз 
будет сокращать количество записей, по которым мы смотрим выборку или что-то считаем. Оптимизация ощутимая.

## Что важно учитывать

1. Если из таблицы источника данные удалить:

```sql
ALTER TABLE responses DELETE WHERE time='2021-10-11 12:00:00'
```

то на МП это НЕ повлияет, удаляейте ручками:

```sql
SELECT * FROM responses_by_sec ORDER BY day ASC

┌─────────────────day─┬─app────┬─status─┬─count─┐
│ 2021-10-11 12:00:00 │ api    │    200 │     1 │
│ 2021-10-11 12:00:00 │ api    │    500 │     1 │
│ 2021-10-11 12:00:00 │ auth   │    200 │     1 │
│ 2021-10-11 12:00:00 │ search │    200 │     3 │
│ 2021-10-11 12:00:01 │ api    │    403 │     1 │
│ 2021-10-11 12:00:01 │ api    │    200 │     2 │
│ 2021-10-11 12:00:01 │ auth   │    500 │     1 │
│ 2021-10-11 12:00:01 │ auth   │    200 │     1 │
│ 2021-10-11 12:00:01 │ search │    200 │     2 │
│ 2021-10-11 12:00:02 │ api    │    200 │     1 │
│ 2021-10-11 12:00:02 │ auth   │    200 │     1 │
│ 2021-10-11 12:00:02 │ search │    200 │     1 │
│ 2021-10-11 12:00:02 │ search │    500 │     1 │
│ 2021-10-11 12:00:03 │ auth   │    200 │     1 │
│ 2021-10-11 12:00:03 │ auth   │    403 │     1 │
└─────────────────────┴────────┴────────┴───────┘
```

2. Агрегация идет ТОЛЬКО на данные, которые вы вставляете в текущей пачке. То есть если вставить данные за одно и тоже время, но разными запросами, 
то они не просуммируются между собой. Это же касается любых других агрегирующих функций. Вероятно за счет таких жертв обеспечивается очень высокая 
скорость вставки. 

**Варианты решения:**
- Накапливать пачку за одну секунду и кидать ее разом в CH. Это кстати наиболее предпочтительный способ с точки зрения производительности.
- Заполнять агрегированную таблицу не с помощью МП а руками, скажем по крону раз в минуту брать данные за прошлую минуту и, нужным образом обработав, вставлять в агрегат:

```sql
INSERT INTO responses_by_sec (day, app, status, count) 
SELECT
    time AS day,
    app,
    status,
    count(*) AS count
FROM responses
GROUP BY
    time,
    app,
    status
```

[В следующей части]({{< ref "/posts/2021/oct/2_clickhouse_replmt.md" >}}) будет рассмотрен движок `ReplacingMergeTree`.